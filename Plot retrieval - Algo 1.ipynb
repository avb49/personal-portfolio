{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\LONAB78\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataframe from csv containing movies and their plots\n",
    "dataframe = pd.read_csv(\"wiki_movie_plots_deduped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records:\n",
      "34886\n",
      "Dataframe columns:\n",
      "['Release Year', 'Title', 'Origin/Ethnicity', 'Director', 'Cast', 'Genre', 'Wiki Page', 'Plot']\n"
     ]
    }
   ],
   "source": [
    "# get dataframe details\n",
    "print(\"Number of records:\")\n",
    "print(len(dataframe))\n",
    "print(\"Dataframe columns:\")\n",
    "print(list(dataframe.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column names\n",
    "dataframe.columns = ['Release_Year',\n",
    " 'Title',\n",
    " 'Origin_Ethnicity',\n",
    " 'Director',\n",
    " 'Cast',\n",
    " 'Genre',\n",
    " 'Wiki_Page',\n",
    " 'Plot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get movies from 1970 and onwards\n",
    "updated_df = dataframe.query('Release_Year >= 1970')\n",
    "\n",
    "# get movies from the following origins: America, Australia, Britain and Canada\n",
    "updated_df = updated_df.query('Origin_Ethnicity == \"American\" | Origin_Ethnicity == \"Australian\"' + \n",
    "                             '| Origin_Ethnicity == \"British\" | Origin_Ethnicity == \"Canadian\"')\n",
    "\n",
    "updated_df = updated_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of all plots\n",
    "list_of_plots = updated_df['Plot'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movie plots:\n",
      "11866\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of movie plots:\")\n",
    "print(len(list_of_plots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tagged_sentence = nltk.tag.pos_tag(text1.split())\n",
    "#edited_sentence = [word for word,tag in tagged_sentence if tag != 'NNP' and tag != 'NNPS']\n",
    "#new_sentence = ' '.join(edited_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n"
     ]
    }
   ],
   "source": [
    "# include proper nouns in stopwords, as arguably these are not needed when comparing similarities of\n",
    "# movie plots. Perhaps cities are useful, but names such as Kevin are not good because their inclusion\n",
    "# means that e.g. other movies than Home Alone with a character named Kevin will be deemed similar to\n",
    "# Home Alone, even though the rest of the plot may be completely different.\n",
    "updated_list_of_plots = []\n",
    "for movie_plot_index in range(0, len(list_of_plots)):\n",
    "    \n",
    "    if(movie_plot_index%500 == 0):\n",
    "        print(movie_plot_index)\n",
    "    tagged_text = nltk.tag.pos_tag(list_of_plots[movie_plot_index].split())\n",
    "    edited_text = [word for word,tag in tagged_text if tag != 'NNP' and tag != 'NNPS']\n",
    "    \n",
    "    # update each movie plot to have proper nouns removed\n",
    "    edited_text = ' '.join(edited_text)\n",
    "    updated_list_of_plots.append(edited_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of stopwords from the English language\n",
    "stop_words = list(ENGLISH_STOP_WORDS)\n",
    "# create instance of tfidf vectoriser class based on list of stopwords\n",
    "vectoriser = TfidfVectorizer(stop_words=stop_words)\n",
    "# call fit function to tokenise (learn idf) and build vocabulary from corpus\n",
    "vectoriser.fit(updated_list_of_plots)\n",
    "\n",
    "# print vocabulary\n",
    "# print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorise each plot based on vectoriser made on movie plot set\n",
    "\n",
    "list_of_vectors = []\n",
    "\n",
    "for plot in updated_list_of_plots:\n",
    "    # vectorise text based on vectoriser created earlier\n",
    "    vector = vectoriser.transform([plot])\n",
    "    list_of_vectors.append(vector)\n",
    "    # summarize vectorised vector\n",
    "    # print(vector.shape)\n",
    "    # print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append list of vectors to dataframe\n",
    "updated_df['vector'] = list_of_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the cosine similarity of two vectorised texts\n",
    "def compare_texts(vector1, vector2):\n",
    "    \n",
    "    cosineSimilarities = cosine_similarity(vector1, vector2)\n",
    "    return cosineSimilarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dataframe with 10 movies most similar to the input movie from the given dataframe\n",
    "# NB: update function to have number of movies to return as an argument \n",
    "def get_top_n_similar_texts(n, vector, dataframe):\n",
    "    \n",
    "    list_of_similarities = []\n",
    "    for index, row in dataframe.iterrows():\n",
    "        similarity_measure = compare_texts(row['vector'], vector)\n",
    "        list_of_similarities.append(similarity_measure)\n",
    "        \n",
    "    # append list of similarities to dataframe\n",
    "    dataframe['similarity'] = list_of_similarities\n",
    "    \n",
    "    # sort dataframe based on similarity measure in descending order\n",
    "    dataframe = dataframe.sort_values('similarity', ascending=False)\n",
    "    \n",
    "    # get top N rows of dataframe\n",
    "    dataframe = dataframe.head(n)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select movie here\n",
    "updated_df.query('Title == \"Toy Story\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = 4066\n",
    "vector_to_compare = updated_df['vector'].iloc[vector_index]\n",
    "df_copy = updated_df.copy()\n",
    "similarity_dataframe = get_top_n_similar_texts(10, vector_to_compare, df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_list_of_plots[4066]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = 89\n",
    "vector_to_test = updated_df['vector'].iloc[vector_index]\n",
    "max_cosine = 0.0\n",
    "new_index = 0\n",
    "\n",
    "for index, row in updated_df.iterrows():\n",
    "    similarity = compare_texts(row['vector'], vector_to_test)\n",
    "    if index == vector_index:\n",
    "        continue\n",
    "    if similarity > max_cosine:\n",
    "        max_cosine = similarity\n",
    "        new_index = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df.iloc[new_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom vector\n",
    "custom_plot = \"Child is left home alone during Christmas. Thieves break into his house as his parents are not home and he has to defend himself.\"\n",
    "vector_custom = vectoriser.transform([custom_plot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cosine = 0.0\n",
    "new_index = 0\n",
    "\n",
    "for index, row in updated_df.iterrows():\n",
    "    similarity = compare_texts(row['vector'], vector_custom)\n",
    "    \n",
    "    if similarity > max_cosine:\n",
    "        max_cosine = similarity\n",
    "        new_index = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df.iloc[new_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. vectorise each text using tfidf and attach list of vectorised texts to dataframe\n",
    "# 3. input a given string (own plot) and vectorise using tfidf\n",
    "# 3. use a for loop to go through each text and get cosine similarity of given string to each text in the dataframe.\n",
    "# Return the most similar plot and its movie details"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
